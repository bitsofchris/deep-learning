# 2024-11-14 - Encoder and Decoder
Started the book, first time actually making progress on it now. 

Quick Recap of the intro I read so far
- Gen AI is a field within Deep Learning and ML. Deep learning is a field within ML, ML is a field within AI.
- Building a LLM -> pretrain a foundation model, fine-tune for your task with labeled data
- Transformer architecture has an encoder (takes input text, encodes into vectors) and a decoder (takes previously decoded text and encoded vector to generate next token).
- BERT & GPT are specific types of Transformers suited for different tasks


Didn't get deep into things yet but after a few pages - I can tell this is a great book and I'm glad I did the Neural Networks and Deep learning first.


Notes will be [here](../notes/deep-learning/llms_from_scratch.md)
